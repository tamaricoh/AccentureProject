{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Conda Environment with Python 3.12 and Installing Required Libraries\n",
    "##### Step 1 - Created a Conda Environment with Python 3.12 and Connected to its Kernel\n",
    "I created a new Conda environment with Python 3.12 and activated it. After that, I connected to the Python kernel in Jupyter/VSCode using this environment.\n",
    "\n",
    "Commands to create and activate the environment:\n",
    "```bash\n",
    "conda create -n llm_env python=3.12\n",
    "conda activate llm_env\n",
    "```\n",
    "\n",
    "##### Step 2 - Imported Required Libraries\n",
    "Once the environment was set up and activated, I imported the following libraries for my project:\n",
    "- `numpy` as `np`: For numerical operations and working with arrays.\n",
    "- `pandas` as `pd`: For data manipulation and analysis.\n",
    "- `torch`: PyTorch, for deep learning model building and training.\n",
    "- `tqdm.notebook`: For displaying progress bars in Jupyter notebooks.\n",
    "- `sklearn.preprocessing.LabelEncoder`: For encoding categorical labels into numerical format.\n",
    "- `sklearn.model_selection.train_test_split`: For splitting datasets into training and testing sets.\n",
    "- `transformers.BertTokenizer`: For tokenizing text data for BERT models.\n",
    "- `transformers.BertForSequenceClassification`: For using BERT for sequence classification tasks.\n",
    "- `torch.utils.data.TensorDataset`: For creating datasets from tensors.\n",
    "- `torch.utils.data.DataLoader`: For batching datasets and loading them efficiently during training.\n",
    "- `torch.utils.data.RandomSampler` and `torch.utils.data.SequentialSampler`: For random and sequential sampling of datasets.\n",
    "- `transformers.AdamW` and `transformers.get_linear_schedule_with_warmup`: For the AdamW optimizer and learning rate scheduler used with transformers.\n",
    "- `sklearn.metrics.f1_score`: For evaluating model performance using the F1 score.\n",
    "- `random`: For random number generation, typically used in data shuffling.\n",
    "\n",
    "Commands to install the libraries:\n",
    "```bash\n",
    "conda install numpy pandas scikit-learn tqdm pytorch\n",
    "conda install -c huggingface transformers\n",
    "```\n",
    "\n",
    "Once the libraries were installed, I successfully imported them into the notebook and was ready to proceed with building and training the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 4\n",
    "learning_rate = 5e-5\n",
    "num_folds  = 5 \n",
    "batch_size = 16\n",
    "# output_model_path = \"bert_model_final.pth\"\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_model_path = f\"model_{timestamp}.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the model to be deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load and Handling\n",
    "\n",
    "- **`df`**: The full dataset loaded from the CSV (`dataset.csv`).\n",
    "- **`labels`**: The list of labels (i.e., 'Artifact Id') extracted from the dataset.\n",
    "- **`label_counts`**: The count of occurrences of each unique label in the dataset.\n",
    "- **`filtered_labels`**: The labels that appear at least 5 times in the dataset.\n",
    "- **`filtered_labels_list`**: A list of labels that appear at least 5 times.\n",
    "- **`filtered_df`**: The filtered DataFrame containing only the rows with labels that appear at least 5 times.\n",
    "\n",
    "By running this script, you get a new DataFrame, `filtered_df`, containing only the rows with labels that appear 5 or more times in the original dataset.\n",
    "\n",
    "**Note**: This is a very simple preprocessing step where we filter out labels with fewer than 5 occurrences. There is no further data cleaning, such as handling missing values or data normalization, applied at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# labels = df['Artifact Id']\n",
    "\n",
    "# label_counts = labels.value_counts()\n",
    "\n",
    "# filtered_labels = label_counts[label_counts >= 5]\n",
    "\n",
    "# filtered_labels_list = filtered_labels.index.tolist()\n",
    "\n",
    "# filtered_df = df[df['Artifact Id'].isin(filtered_labels_list)]\n",
    "\n",
    "# print(filtered_df['Artifact Id'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for Overfitting on a Small Portion of the Data\n",
    "\n",
    "In this part of the code, we filter the dataset to only include labels that have exactly **16 samples**. By training the model on this small subset, we aim to observe if it achieves **overfitting**, where it memorizes the data rather than generalizing well. This helps us test the model's ability to avoid overfitting on limited data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# labels = df['Artifact Id']\n",
    "\n",
    "# label_counts = labels.value_counts()\n",
    "\n",
    "# filtered_labels = label_counts[label_counts == 16]\n",
    "\n",
    "# filtered_labels_list = filtered_labels.index.tolist()\n",
    "\n",
    "# filtered_df = df[df['Artifact Id'].isin(filtered_labels_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the Dataset\n",
    "\n",
    "To address class imbalance in the dataset, we performed the following steps:\n",
    "\n",
    "1. **Random Sampling of 'Command' Class**: We noticed that the **'d3f:Command'** class was underrepresented in the dataset. Therefore, we **randomly sampled 16 instances** from this class to ensure it is adequately represented.\n",
    "\n",
    "2. **Combining the Data**: After sampling the 'Command' class, we combined it with the filtered dataset to create a **more balanced dataset**.\n",
    "\n",
    "This process ensures that the model is not biased towards the larger classes and helps it generalize better across all classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifact Id\n",
      "d3f:Database                     16\n",
      "d3f:Software                     16\n",
      "d3f:Command                      16\n",
      "d3f:HardwareDriver               14\n",
      "d3f:DisplayServer                11\n",
      "d3f:OperatingSystem               8\n",
      "d3f:FileSystem                    7\n",
      "d3f:BootLoader                    6\n",
      "d3f:InterprocessCommunication     5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "labels = df['Artifact Id']\n",
    "\n",
    "label_counts = labels.value_counts()\n",
    "\n",
    "filtered_labels = label_counts[(label_counts >= 5) & (label_counts <= 200)] # Remove \"Command\" label\n",
    "\n",
    "filtered_labels_list = filtered_labels.index.tolist()\n",
    "\n",
    "filtered_df = df[df['Artifact Id'].isin(filtered_labels_list)]\n",
    "\n",
    "command_df = df[df['Artifact Id'] == 'd3f:Command']\n",
    "sample_size = min(len(command_df), 16)\n",
    "sampled_command_df = command_df.sample(n=sample_size, random_state=42)\n",
    "combined_df = pd.concat([filtered_df, sampled_command_df])\n",
    "\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(combined_df['Artifact Id'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide to Train, Validation, and Test While Keeping the Distribution\n",
    "\n",
    "In this step, the dataset is split into a training set, a validation set, and a testing set, while maintaining the same label distribution across all sets. This is done using the `train_test_split` function from `sklearn.model_selection`, with the `stratify` parameter set to the labels (`Artifact Id`) to ensure that all splits preserve the same class proportions as the original dataset.\n",
    "\n",
    "- **Training Set**: Contains 64% of the data.\n",
    "- **Validation Set**: Contains 16% of the data.\n",
    "- **Test Set**: Contains 20% of the data.\n",
    "\n",
    "By using stratified splitting, the label distribution in all sets (training, validation, and test) is consistent, preventing potential bias caused by imbalanced labels in smaller datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, test_df = train_test_split(filtered_df,\n",
    "#                                      test_size=0.2,\n",
    "#                                      stratify=filtered_df['Artifact Id'],\n",
    "#                                      random_state=42)\n",
    "\n",
    "# train_df, val_df = train_test_split(train_df,\n",
    "#                                     test_size=0.2,\n",
    "#                                     stratify=train_df['Artifact Id'],\n",
    "#                                     random_state=42)\n",
    "\n",
    "train_val_df, test_df = train_test_split(filtered_df,\n",
    "                                         test_size=0.2,\n",
    "                                         stratify=filtered_df['Artifact Id'],\n",
    "                                         random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Training set label distribution:\")\n",
    "# print(train_df['Artifact Id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nValidation set label distribution:\")\n",
    "# print(val_df['Artifact Id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nTest set label distribution:\")\n",
    "# print(test_df['Artifact Id'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Tokenizer Initialization\n",
    "\n",
    "- **Model**: A pre-trained `BertForSequenceClassification` model is loaded from `bert-base-uncased`, with a classification head set to `num_labels` (number of unique labels in the dataset).\n",
    "\n",
    "- **Tokenizer**: The `BertTokenizer` for `bert-base-uncased` is used for consistent tokenization.\n",
    "\n",
    "These components enable fine-tuning of the BERT model for the multiclass classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BertForSequenceClassification.from_pretrained(\n",
    "#     'bert-base-uncased', num_labels=len(filtered_labels_list))\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation: Tokenization and Dataloader Creation\n",
    "\n",
    "- **`tokenize_data`**: Tokenizes input text using the BERT tokenizer, padding and truncating to a max length of 512 tokens, and returns PyTorch tensors.\n",
    "\n",
    "- **Tokenization**: The training, validation, and test data (`'Example Description'`) are tokenized into input IDs and attention masks.\n",
    "\n",
    "- **Label Encoding**: Labels (`'Artifact Id'`) are mapped to indices and converted to tensor labels for all datasets.\n",
    "\n",
    "- **Dataset Creation**: `TensorDataset` objects are created for training, validation, and test data with tokenized inputs and labels.\n",
    "\n",
    "- **DataLoader**: Three DataLoaders are created:\n",
    "  - `train_loader`: Random sampling for training.\n",
    "  - `val_loader` and `test_loader`: Sequential sampling for validation and testing, with a batch size of 16.\n",
    "\n",
    "These steps prepare the data for efficient use in training, validation, and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(texts, tokenizer):\n",
    "    return tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "# # Tokenize the training, validation, and test data\n",
    "# train_encodings = tokenize_data(train_df['Example Description'].tolist())\n",
    "# val_encodings = tokenize_data(val_df['Example Description'].tolist())  # Validation set\n",
    "# test_encodings = tokenize_data(test_df['Example Description'].tolist())\n",
    "\n",
    "# # Convert labels to tensors\n",
    "# train_labels = torch.tensor(train_df['Artifact Id'].map(lambda x: filtered_labels_list.index(x)).tolist())\n",
    "# val_labels = torch.tensor(val_df['Artifact Id'].map(lambda x: filtered_labels_list.index(x)).tolist())  # Validation set\n",
    "# test_labels = torch.tensor(test_df['Artifact Id'].map(lambda x: filtered_labels_list.index(x)).tolist())\n",
    "\n",
    "# train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
    "# val_dataset = TensorDataset(val_encodings['input_ids'], val_encodings['attention_mask'], val_labels)  # Validation set\n",
    "# test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=16)\n",
    "# val_loader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=16)  # Validation set\n",
    "# test_loader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Learning Rate Scheduler\n",
    "\n",
    "- **Optimizer**: \n",
    "  - `AdamW` is used, suitable for fine-tuning transformer models like BERT, with a learning rate of `5e-5`.\n",
    "  \n",
    "- **Learning Rate Scheduler**: \n",
    "  - A linear scheduler adjusts the learning rate over `total_steps` (batches × epochs), with no warm-up phase (`num_warmup_steps=0`).\n",
    "\n",
    "These components ensure efficient model optimization during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# total_steps = len(train_loader) * num_epochs\n",
    "\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function\n",
    "\n",
    "This function trains the model for a specified number of epochs:\n",
    "\n",
    "1. **Forward Pass**: For each batch, the model computes the loss and logits, then makes predictions by selecting the class with the highest logit.\n",
    "2. **Metrics Calculation**: It tracks the total loss, accuracy, and F1 score across all batches in each epoch. Accuracy is calculated by comparing the predicted labels to the true labels, and the F1 score is computed using the weighted average across all classes.\n",
    "3. **Optimization**: The model parameters are updated using backpropagation (`loss.backward()`), and the optimizer and learning rate scheduler are updated each step.\n",
    "\n",
    "At the end of each epoch, the loss, accuracy, and F1 score are printed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, scheduler, device, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids, attention_mask, labels = [item.to(device) for item in batch]\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            # Store predictions and labels for F1 score calculation\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "            # Accuracy calculation\n",
    "            correct = (preds == labels).sum().item()\n",
    "            total_correct += correct\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Calculate metrics for the epoch\n",
    "        accuracy = total_correct / total_samples * 100\n",
    "        f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}, Accuracy: {accuracy:.2f}%, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with Validation\n",
    "\n",
    "The `train_with_validation` function trains the model for multiple epochs and evaluates it on a validation set after each epoch. \n",
    "\n",
    "1. **Training**: For each batch, the model computes the loss, updates parameters, and tracks accuracy and F1 score.\n",
    "2. **Validation**: After each epoch, the model's performance is evaluated on the validation set, and validation accuracy and F1 score are calculated.\n",
    "\n",
    "Metrics (training and validation accuracy, F1 score) are printed after each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_validation(model, train_loader, val_loader, optimizer, scheduler, device, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids, attention_mask, labels = [item.to(device) for item in batch]\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "            correct = (preds == labels).sum().item()\n",
    "            total_correct += correct\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Calculate training metrics\n",
    "        accuracy = total_correct / total_samples * 100\n",
    "        f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_samples = 0\n",
    "        val_all_labels = []\n",
    "        val_all_preds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Validating Epoch {epoch+1}/{num_epochs}\"):\n",
    "                input_ids, attention_mask, labels = [item.to(device) for item in batch]\n",
    "\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "\n",
    "                preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "                val_all_preds.extend(preds.cpu().tolist())\n",
    "                val_all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "                correct = (preds == labels).sum().item()\n",
    "                val_correct += correct\n",
    "                val_samples += labels.size(0)\n",
    "\n",
    "        val_accuracy = val_correct / val_samples * 100\n",
    "        val_f1 = f1_score(val_all_labels, val_all_preds, average=\"weighted\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.6f}, Accuracy: {accuracy:.6f}%, F1 Score: {f1:.6f}\")\n",
    "        print(f\"Validation Accuracy: {val_accuracy:.6f}%, Validation F1 Score: {val_f1:.6f}\")\n",
    "\n",
    "    return val_accuracy, val_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(\n",
    "#     model=model,\n",
    "#     train_loader=train_loader,\n",
    "#     optimizer=optimizer,\n",
    "#     scheduler=scheduler,\n",
    "#     device=device,\n",
    "#     num_epochs=num_epochs\n",
    "# )\n",
    "\n",
    "# train_with_validation(\n",
    "#     model=model,\n",
    "#     train_loader=train_loader,\n",
    "#     val_loader=val_loader,\n",
    "#     optimizer=optimizer,\n",
    "#     scheduler=scheduler,\n",
    "#     device=device,\n",
    "#     num_epochs=num_epochs\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "After training, the model is evaluated on the test set to assess its performance on unseen data. During this phase, the model is set to evaluation mode using `model.eval()`, and predictions are made on the test set.\n",
    "\n",
    "- **Prediction**: For each batch in the test set, the model generates predictions (logits), which are converted to class labels using `torch.argmax()`.\n",
    "  \n",
    "- **F1 Score**: The F1 score, calculated using the `f1_score` function from `sklearn.metrics`, is reported to measure the weighted average performance across all classes.\n",
    "  \n",
    "- **Accuracy**: The accuracy of the model is calculated by comparing the predicted labels to the true labels and computing the percentage of correct predictions.\n",
    "\n",
    "The evaluation results help in understanding the model's effectiveness and generalization to the test set.\n",
    "\n",
    "*Note: This evaluation process does not update the model parameters, ensuring that it is a true test of performance.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            input_ids, attention_mask, labels = [item.to(device) for item in batch]\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate F1 score (weighted) for multiclass classification\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = np.sum(np.array(predictions) == np.array(true_labels)) / len(true_labels) * 100\n",
    "\n",
    "    print(f\"F1 Score (Weighted): {f1:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### K-Fold Cross Validation with BERT\n",
    "\n",
    "This code performs **K-Fold Cross Validation** using **StratifiedKFold** for evaluating a BERT-based model on a classification task. For each fold, it:\n",
    "\n",
    "1. Splits the dataset into training and validation sets.\n",
    "2. Tokenizes the input text (e.g., \"Example Description\").\n",
    "3. Prepares and loads data into `DataLoader` for training and validation.\n",
    "4. Initializes the BERT model and optimizer, and trains the model for a specified number of epochs.\n",
    "5. Evaluates the model on the validation set using **F1 score** (weighted) and **accuracy**.\n",
    "6. Computes average metrics across all folds.\n",
    "\n",
    "Finally, the trained model is evaluated on a test set, and the final performance metrics are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encodings = tokenize_data(test_df['Example Description'].tolist(), tokenizer)\n",
    "label_mapping = {label: idx for idx, label in enumerate(filtered_labels_list)}\n",
    "test_labels = torch.tensor([label_mapping.get(x, -1) for x in test_df['Artifact Id']])\n",
    "test_dataset = TensorDataset(\n",
    "    test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)\n",
    "test_loader = DataLoader(test_dataset, sampler=SequentialSampler(\n",
    "    test_dataset), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tamar\\anaconda3\\envs\\llm_env\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\tamar\\anaconda3\\envs\\llm_env\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe2720664004700814a43171e134dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a9a12fbed043d3bd18c233d77b6629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 1/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.109997, Accuracy: 5.769231%, F1 Score: 0.019231\n",
      "Validation Accuracy: 14.285714%, Validation F1 Score: 0.035714\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f7a91597e94eedb60ceb5a6205478a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da80f09c1ee4fe9843c15d8fd6dd58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 2/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.914670, Accuracy: 26.923077%, F1 Score: 0.247165\n",
      "Validation Accuracy: 21.428571%, Validation F1 Score: 0.145238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe2eb05a3df48fe94cc72331e8df9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d91c51ec1f4fd9a34b7e239d063e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 3/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.823328, Accuracy: 40.384615%, F1 Score: 0.346009\n",
      "Validation Accuracy: 21.428571%, Validation F1 Score: 0.145238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9aaaa9ecd5147e19e510518885247c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71087645a13e43c096dca255e642c75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 4/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.752580, Accuracy: 40.384615%, F1 Score: 0.341999\n",
      "Validation Accuracy: 28.571429%, Validation F1 Score: 0.243197\n",
      "\n",
      "--- Fold 2/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\tamar\\anaconda3\\envs\\llm_env\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de36990d3424b829dfe6b1200b2ea0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ff8508592e494fb1d80940c4fc244e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 1/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.168932, Accuracy: 9.433962%, F1 Score: 0.071621\n",
      "Validation Accuracy: 7.692308%, Validation F1 Score: 0.010989\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8938af09914bd6b4263b1becc1fee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81af8734c1a34f15972275aa56a182ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 2/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 2.086761, Accuracy: 22.641509%, F1 Score: 0.187781\n",
      "Validation Accuracy: 23.076923%, Validation F1 Score: 0.127872\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ea2fc3e7504300aee68f56162fe200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3185ebb269241ee95a5578235ce8e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 3/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 2.007686, Accuracy: 20.754717%, F1 Score: 0.167844\n",
      "Validation Accuracy: 23.076923%, Validation F1 Score: 0.092308\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb615e1176eb4bd591ff9e6a88c80559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c4791ba0fe4806abdb5c182e3606a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 4/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 2.073453, Accuracy: 9.433962%, F1 Score: 0.058893\n",
      "Validation Accuracy: 30.769231%, Validation F1 Score: 0.175824\n",
      "\n",
      "--- Fold 3/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\tamar\\anaconda3\\envs\\llm_env\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9928f75dc0e74e0086798bea7980bec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e1c29d4fff4b39bcc836ea906bf551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 1/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.143051, Accuracy: 16.981132%, F1 Score: 0.137793\n",
      "Validation Accuracy: 7.692308%, Validation F1 Score: 0.010989\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54af47c6d3c3438cb0740076faab9d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8170d240ac294d2094f7c5f21e7f0973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 2/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 2.116594, Accuracy: 16.981132%, F1 Score: 0.083490\n",
      "Validation Accuracy: 23.076923%, Validation F1 Score: 0.086538\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0964af246cb246cbb8ba6037439b036f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad849a960872468daaa611749ffa6c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 3/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.989078, Accuracy: 26.415094%, F1 Score: 0.200457\n",
      "Validation Accuracy: 23.076923%, Validation F1 Score: 0.086538\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20a6b006f4e44f38ac562326f329db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b288ae7ea45a4817a8e9a00e404edb5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 4/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.975226, Accuracy: 26.415094%, F1 Score: 0.199404\n",
      "Validation Accuracy: 30.769231%, Validation F1 Score: 0.175824\n",
      "\n",
      "--- Fold 4/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\tamar\\anaconda3\\envs\\llm_env\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d361bab86c740cd8631454f5e09b281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5ab7edf38440d6b8421554cdf88573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 1/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.082476, Accuracy: 20.754717%, F1 Score: 0.137631\n",
      "Validation Accuracy: 23.076923%, Validation F1 Score: 0.098901\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ffe6a9da884e3c8dcbf25079c7f6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3006bbbf160643bbb53783eba94374b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 2/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.931445, Accuracy: 26.415094%, F1 Score: 0.172526\n",
      "Validation Accuracy: 23.076923%, Validation F1 Score: 0.115385\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8d53e7a17e4965b22a922fae3858c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4840b49bf719446f8c7a16bdbb76ca1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 3/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.880448, Accuracy: 30.188679%, F1 Score: 0.237977\n",
      "Validation Accuracy: 15.384615%, Validation F1 Score: 0.120280\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918d886a47e0406e83236b7cc5c1da74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71158015dfba4823a884f18607409a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 4/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.872550, Accuracy: 41.509434%, F1 Score: 0.332038\n",
      "Validation Accuracy: 23.076923%, Validation F1 Score: 0.132867\n",
      "\n",
      "--- Fold 5/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\tamar\\anaconda3\\envs\\llm_env\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ce842bd2744ccfbc2d44aab70769fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6122a6555ba44f989875378d6f9c77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 1/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.101059, Accuracy: 15.094340%, F1 Score: 0.092192\n",
      "Validation Accuracy: 15.384615%, Validation F1 Score: 0.041026\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08111398bda44b2b97e3c1db4a593b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7489a81a4fb747f49098831aa7a826d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 2/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.963122, Accuracy: 28.301887%, F1 Score: 0.150386\n",
      "Validation Accuracy: 30.769231%, Validation F1 Score: 0.145299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7641e0780d55415aac18d22caa6d7264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807c2237767f4041a7a4c7b9fda46f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 3/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.857546, Accuracy: 35.849057%, F1 Score: 0.256866\n",
      "Validation Accuracy: 30.769231%, Validation F1 Score: 0.149451\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b4ae68eaa24e71a3e204dd9d22b4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4/4:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fab94b768e4956b1fbe23c970222bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Epoch 4/4:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.794583, Accuracy: 43.396226%, F1 Score: 0.329977\n",
      "Validation Accuracy: 30.769231%, Validation F1 Score: 0.164835\n",
      "\n",
      "--- K-Fold Results ---\n",
      "Average F1 Score (Weighted): 28.7912\n",
      "Average Accuracy: 0.18%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50993e23a419435ea2fa4479ce4fa05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Weighted): 0.2941\n",
      "Accuracy: 41.18%\n"
     ]
    }
   ],
   "source": [
    "# K-Fold Cross Validation on 80% train/val data\n",
    "best_model = None\n",
    "best_val_f1 = 0.0\n",
    "fold_results = []  # Store F1 score and accuracy for each fold\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(train_val_df, train_val_df['Artifact Id'])):\n",
    "    print(f\"\\n--- Fold {fold+1}/{num_folds} ---\")\n",
    "\n",
    "    # Split the train/val set into training and validation data for this fold\n",
    "    train_df = train_val_df.iloc[train_index]\n",
    "    val_df = train_val_df.iloc[val_index]\n",
    "\n",
    "    # Tokenize the training and validation data\n",
    "    train_encodings = tokenize_data(train_df['Example Description'].tolist(), tokenizer)\n",
    "    val_encodings = tokenize_data(val_df['Example Description'].tolist(), tokenizer)\n",
    "\n",
    "    # Map labels to indices for training and validation\n",
    "    train_labels = torch.tensor(train_df['Artifact Id'].map(\n",
    "        lambda x: filtered_labels_list.index(x)).tolist())\n",
    "    val_labels = torch.tensor(val_df['Artifact Id'].map(\n",
    "        lambda x: filtered_labels_list.index(x)).tolist())\n",
    "\n",
    "    # Create TensorDatasets for training and validation\n",
    "    train_dataset = TensorDataset(\n",
    "        train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
    "    val_dataset = TensorDataset(\n",
    "        val_encodings['input_ids'], val_encodings['attention_mask'], val_labels)\n",
    "\n",
    "    # Create DataLoaders for training and validation\n",
    "    train_loader = DataLoader(train_dataset, sampler=RandomSampler(\n",
    "        train_dataset), batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_dataset, sampler=SequentialSampler(\n",
    "        val_dataset), batch_size=batch_size)\n",
    "\n",
    "    # Initialize model, optimizer, and scheduler\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased', num_labels=len(filtered_labels_list))\n",
    "    model.to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    # Train the model with validation\n",
    "    accuracy, f1 = train_with_validation(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        num_epochs=num_epochs\n",
    "    )\n",
    "    \n",
    "    fold_results.append((accuracy, f1))\n",
    "    if f1 > best_val_f1:\n",
    "        best_val_f1 = f1\n",
    "        best_model = model.state_dict()\n",
    "\n",
    "# # Average results over all folds\n",
    "# average_f1 = np.mean([result[0] for result in fold_results])\n",
    "# average_accuracy = np.mean([result[1] for result in fold_results])\n",
    "# print(f\"\\n--- K-Fold Results ---\")\n",
    "# print(f\"Average F1 Score (Weighted): {average_f1:.4f}\")\n",
    "# print(f\"Average Accuracy: {average_accuracy:.2f}%\")\n",
    "\n",
    "# Test the model on the test set\n",
    "test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), output_model_path)\n",
    "# torch.save({\n",
    "#     'model': model,  # Save the entire model\n",
    "#     'optimizer': optimizer,  # Save the entire optimizer object\n",
    "#     'scheduler': scheduler,  # Save the entire scheduler object\n",
    "#     'tokenizer': tokenizer,  # Save the tokenizer\n",
    "#     'label_mapping': filtered_labels_list  # Save label mappings\n",
    "# }, output_model_path)\n",
    "# print(f\"Model saved to {output_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model_2024-12-03_16-37-16.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': best_model,\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict(),\n",
    "    'tokenizer': tokenizer,\n",
    "    'label_mapping': filtered_labels_list\n",
    "}, output_model_path)\n",
    "print(f\"Model saved to {output_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to test_data.csv\n"
     ]
    }
   ],
   "source": [
    "test_df.to_csv('test_data.csv', index=False)\n",
    "print(\"DataFrame saved to test_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
