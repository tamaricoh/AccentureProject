{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from transformers import BertTokenizer, AdamW\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from pys.functions import CustomBertModel, create_dataset, train_with_validation, test\n",
    "from pys.params import batch_size, learning_rate, num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv('../csv/dataset.csv')\n",
    "baseline_df = pd.read_csv('../csv/baseline.csv')\n",
    "dataset_aug_df = pd.read_csv('../csv/dataset_aug.csv')\n",
    "test_df = pd.read_csv('../csv/cve_data.csv')\n",
    "\n",
    "baseline_descriptions = baseline_df['Example Description'].tolist()\n",
    "\n",
    "filtered_dataset_df = dataset_df[~dataset_df['Example Description'].isin(\n",
    "    baseline_descriptions)]\n",
    "\n",
    "train_df = pd.concat([filtered_dataset_df, dataset_aug_df], ignore_index=True)\n",
    "val_df = baseline_df.copy()\n",
    "test_df = test_df.copy()\n",
    "\n",
    "train_labels = train_df['Artifact Id']\n",
    "val_labels = val_df['Artifact Id']\n",
    "test_labels = test_df['Artifact Id']\n",
    "\n",
    "train_labels_counts = train_labels.value_counts()\n",
    "val_labels_counts = val_labels.value_counts()\n",
    "test_labels_counts = test_labels.value_counts()\n",
    "\n",
    "all_unique_labels = list(set(train_labels.unique().tolist(\n",
    ") + val_labels.unique().tolist() + test_labels.unique().tolist()))\n",
    "\n",
    "label_mapping = {label: idx for idx, label in enumerate(all_unique_labels)}\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_max = 50\n",
    "eta_min = 1e-5\n",
    "output_model_path = \"../models/model_cve_test_baseline_val.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_dataset = create_dataset(train_df, tokenizer, label_mapping)\n",
    "val_dataset = create_dataset(val_df, tokenizer, label_mapping)\n",
    "test_dataset = create_dataset(test_df, tokenizer, label_mapping)\n",
    "\n",
    "model = CustomBertModel(num_labels=len(label_mapping))\n",
    "model.bert.dropout.p = 0.3\n",
    "print(model.bert.dropout.p)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=T_max, eta_min=eta_min)\n",
    "model.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, sampler=RandomSampler(val_dataset), batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n",
    "\n",
    "f1_train, f1_val, acc_train, acc_val, loss_train, loss_val = train_with_validation(\n",
    "    model, train_loader, val_loader, optimizer, device, num_epochs, scheduler\n",
    ")\n",
    "\n",
    "f1_test, acc_test = test(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(acc_train, acc_val, f1_train, f1_val, loss_train, loss_val):\n",
    "  \n",
    "    epochs = range(1, num_epochs + 1)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))  \n",
    "\n",
    "    axes[0].plot(epochs, acc_train, color='blue', linestyle='-', label='Train Accuracy')\n",
    "    axes[0].plot(epochs, acc_val, color='red', linestyle='-', label='Validation Accuracy')\n",
    "    axes[0].set_title('Accuracy Over Epochs')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel('Accuracy (%)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    axes[1].plot(epochs, f1_train, color='blue', linestyle='-', label='Train F1 Score')\n",
    "    axes[1].plot(epochs, f1_val, color='red', linestyle='-', label='Validation F1 Score')\n",
    "    axes[1].set_title('F1 Score Over Epochs')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].set_ylabel('F1 Score')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    axes[2].plot(epochs, loss_train, color='blue', linestyle='-', label='Train Loss')\n",
    "    axes[2].plot(epochs, loss_val, color='red', linestyle='-', label='Validation Loss')\n",
    "    axes[2].set_title('Loss Over Epochs')\n",
    "    axes[2].set_xlabel('Epochs')\n",
    "    axes[2].set_ylabel('Loss')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "\n",
    "    fig.suptitle(f\"Training and Validation Metrics\\n\"\n",
    "                 \"dropout_cve_test_baseline_val.ipynb\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(acc_train, acc_val, f1_train, f1_val, loss_train, loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print training results\n",
    "print(\"\\n--- Training Results ---\")\n",
    "print(f\"Training F1 Score (Weighted): {f1_train[-1]:.4f}\")\n",
    "print(f\"Training Accuracy: {acc_train[-1]:.2f}%\")\n",
    "print(f\"Training Loss: {loss_train[-1]:.4f}\")\n",
    "\n",
    "# Print validation results\n",
    "print(\"\\n--- Validation Results ---\")\n",
    "print(f\"Validation F1 Score (Weighted): {f1_val[-1]:.4f}\")\n",
    "print(f\"Validation Accuracy: {acc_val[-1]:.2f}%\")\n",
    "print(f\"Validation Loss: {loss_val[-1]:.4f}\")\n",
    "\n",
    "# Print test results\n",
    "print(\"\\n--- Test Results ---\")\n",
    "print(f\"Test F1 Score (Weighted): {f1_test:.4f}\")\n",
    "print(f\"Test Accuracy: {acc_test:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
